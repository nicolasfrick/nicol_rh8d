#!/usr/bin/env python
from dynamic_reconfigure.parameter_generator_catkin import *

gen = ParameterGenerator()

corner_refine_enum = gen.enum(
                                          [ gen.const("CORNER_REFINE_NONE",  int_t, 0, "Tag and corners detection based on the ArUco approach. "),
                                            gen.const("CORNER_REFINE_SUBPIX", int_t, 1, "ArUco approach and refine the corners locations using corner subpixel accuracy. "),
                                            gen.const("CORNER_REFINE_CONTOUR", int_t, 2, "ArUco approach and refine the corners locations using the contour-points line fitting."),
                                            gen.const("CORNER_REFINE_APRILTAG", int_t, 3, "Tag and corners detection based on the AprilTag 2 approach") ],
                                            "Enum to set Aruco corner refine method")

pattern_enum = gen.enum(
                                          [ gen.const("ARUCO_CCW_CENTER",  int_t, 0, "Estimate marker center"),
                                            gen.const("ARUCO_CW_TOP_LEFT_CORNER", int_t, 1, "Estimate top left marker corner") ],
                                            "Enum to set Aruco estimate pattern")

solver_enum = gen.enum(
                                          [ gen.const("SOLVEPNP_ITERATIVE",int_t, 0," Iterative method is based on a Levenberg-Marquardt optimization. In this case the function finds such a pose that minimizes reprojection error, that is the sum of squared distances between the observed projections imagePoints and the projected (using cv::projectPoints ) objectPoints. Initial solution for non-planar objectPoints needs at least 6 points and uses the DLT algorithm. Initial solution for planar objectPoints needs at least 4 points and uses pose from homography decomposition."),
                                            gen.const("SOLVEPNP_EPNP",int_t, 1,""),
                                            gen.const("SOLVEPNP_P3P",int_t, 2,"In this case the function requires exactly four object and image points."),
                                            gen.const("SOLVEPNP_DLS",int_t, 3,"Broken implementation. Using this flag will fallback to EPnP."),
                                            gen.const("SOLVEPNP_UPNP",int_t, 4,". In this case the function also estimates the parameters and assuming that both have the same value. Then the cameraMatrix is updated with the estimated focal length."),
                                            gen.const("SOLVEPNP_AP3P",int_t, 5,"In this case the function requires exactly four object and image points."),
                                            gen.const("SOLVEPNP_IPPE",int_t, 6,"This method requires coplanar object points."),
                                            gen.const("SOLVEPNP_IPPE_SQUARE",int_t, 7,"This method is suitable for marker pose estimation. It requires 4 coplanar object points"),
                                            gen.const("SOLVEPNP_SQPNP",int_t, 8,"It requires 3 or more points."),
                                            gen.const("SOLVEPNP_MAX_COUNT",int_t, 9,"") ],
                                            "Enum to set Aruco solver method")

# name paramtype (any of int_t, double_t, str_t, or bool_t) level  description  default min max (optional and does not apply to strings and bools) 
# denoise
den_group = gen.add_group("image denoising")
den_group.add('denoise', bool_t, 0, 'enable image denoising.', False)
den_group.add('h', double_t, 0, 	'Parameter regulating filter strength. Big h value perfectly removes noise but also removes image details, smaller h value preserves details but also preserves some noise', 10.0, 0.0 ,100.0)
den_group.add('templateWindowSize', int_t, 0, '	Size in pixels of the template patch that is used to compute weights. Should be odd.', 7, 1 ,100)
den_group.add('searchWindowSize', int_t, 0, '	Size in pixels of the window that is used to compute weighted average for given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater denoising time', 21, 1 ,100)
# estimator
# est_group = gen.add_group("pose estimation")
# est_group.add('pattern', int_t, 0, 'Estimate the center or the top left corner of a marker as coordinate center', 0, 0 ,1, edit_method=pattern_enum)
# est_group.add('solvePnPMethod', int_t, 0, 'Method for the pnp solver', 7, 0 ,9, edit_method=solver_enum)
# detector
det_group = gen.add_group("marker detection")
det_group.add('adaptiveThreshWinSizeMin', int_t, 0, 'minimum window size for adaptive thresholding before finding contours', 3, 3 ,100)
det_group.add('adaptiveThreshWinSizeMax', int_t, 0, 'maximum window size for adaptive thresholding before finding contours', 23, 3 ,100)
det_group.add('adaptiveThreshWinSizeStep', int_t, 0, 'increments from adaptiveThreshWinSizeMin to adaptiveThreshWinSizeMax during the thresholding', 10, 1 ,100)
det_group.add('adaptiveThreshConstant', double_t, 0, 'constant for adaptive thresholding before finding contours', 7.0, 0 ,100)
det_group.add('minMarkerPerimeterRate', double_t, 0, 'determine minimum perimeter for marker contour to be detected', 0.03, 0.001 ,1.0)
det_group.add('maxMarkerPerimeterRate', double_t, 0, 'determine maximum perimeter for marker contour to be detected, defined as a rate wrt. the maximum dimension of the input image', 4.0, 0.001 ,10)
det_group.add('polygonalApproxAccuracyRate', double_t, 0, 'minimum accuracy during the polygonal approximation process to determine which contours are squares', 0.03, 0.001 ,1.0)
det_group.add('minCornerDistanceRate', double_t, 0, 'minimum distance between corners for detected markers relative to its perimeter', 0.05, 0.001 ,1.0)
det_group.add('minDistanceToBorder', int_t, 0, 'minimum distance of any corner to the image border for detected markers', 3, 1 ,10)
det_group.add('minMarkerDistanceRate', double_t, 0, 'minimum average distance between the corners of the two markers to be grouped', 0.125, 0 ,1.0)
det_group.add('minGroupDistance', double_t, 0, 'minimum average distance between the corners of the two markers in group to add them to the list of candidates', 0.21, 0 ,1.0)
det_group.add('cornerRefinementMethod', int_t, 0, '', 3, 0 ,3, edit_method=corner_refine_enum)
det_group.add('cornerRefinementWinSize', int_t, 0, 'maximum window size for the corner refinement process (in pixels)', 5, 0 ,10)
det_group.add('relativeCornerRefinmentWinSize', double_t, 0, 'dynamic window size for corner refinement relative to Aruco module size', 0.3, 0 ,1.0) # The final window size is calculated as: min(cornerRefinementWinSize, averageArucoModuleSize*relativeCornerRefinmentWinSize), where averageArucoModuleSize is average module size of ArUco marker in pixels. (ArUco marker is composed of black and white modules) In the case of markers located far from each other, it may be useful to increase the value of the parameter to 0.4-0.5. In the case of markers located close to each other, it may be useful to decrease the parameter value to 0.1-0.2. 
det_group.add('cornerRefinementMaxIterations', int_t, 0, 'maximum number of iterations for stop criteria of the corner refinement process', 30, 0 ,100)
det_group.add('cornerRefinementMinAccuracy', double_t, 0, 'minimum error for the stop cristeria of the corner refinement process', 0.1, 0 ,1.0)
det_group.add('markerBorderBits', int_t, 0, 'number of bits of the marker border, i.e. marker border width', 1, 1 ,10)
det_group.add('perspectiveRemovePixelPerCell', int_t, 0, 'number of bits (per dimension) for each cell of the marker when removing the perspective', 4, 0 ,10)
det_group.add('perspectiveRemoveIgnoredMarginPerCell', double_t, 0, 'width of the margin of pixels on each cell not considered for the determination of the cell bit, represents the rate respect to the total size of the cell, i.e. perspectiveRemovePixelPerCell', 0.13, 0 ,1.0)
det_group.add('maxErroneousBitsInBorderRate', double_t, 0, 'maximum number of accepted erroneous bits in the border (i.e. number of allowed white bits in the border), represented as a rate respect to the total number of bits per marker', 0.35, 0 ,1.0)
det_group.add('minOtsuStdDev', double_t, 0, 'minimun standard deviation in pixels values during the decodification step to apply Otsu thresholding (otherwise, all the bits are set to 0 or 1 depending on mean higher than 128 or not)', 5.0, 0 ,100)
det_group.add('errorCorrectionRate', double_t, 0, 'error correction rate respect to the maximun error correction capability for each dictionary', 0.6, 0 ,1.0)
det_group.add('aprilTagQuadDecimate', double_t, 0, 'Detection of quads can be done on a lower-resolution image, improving speed at a cost of pose accuracy and a slight decrease in detection rate. Decoding the binary payload is still', 0.0, 0 ,10)
det_group.add('aprilTagQuadSigma', double_t, 0, 'what Gaussian blur should be applied to the segmented image (used for quad detection?)', 0.0, 0 ,1.0)
det_group.add('aprilTagMinClusterPixels', int_t, 0, 'reject quads containing too few pixels', 5, 0 ,100)
det_group.add('aprilTagMaxNmaxima', int_t, 0, 'how many corner candidates to consider when segmenting a group of pixels into a quad',10, 0 ,100)
det_group.add('aprilTagCriticalRad', double_t, 0, 'reject quads where pairs of edges have angles that are close to straight or close to 180 degrees, zero means that no quads are rejected (In radians)', 0.1745329201221466, 0 ,1.57)
det_group.add('aprilTagMaxLineFitMse', double_t, 0, 'when fitting lines to the contours, what is the maximum mean squared error', 10.0, 0 ,100)
det_group.add('aprilTagMinWhiteBlackDiff', int_t, 0, 'add an extra check that the white model must be (overall) brighter than the black model, when we build our model of black & white pixels, we add an extra check that the white model must be (overall) brighter than the black model. How much brighter? (in pixel values, [0,255])', 5, 0 ,255)
det_group.add('aprilTagDeglitch', int_t, 0, 'should the thresholded image be deglitched? Only useful for very noisy images', 0, 0 ,10)
det_group.add('detectInvertedMarker', bool_t, 0, 'to check if there is a white marker, In order to generate a "white" marker just invert a normal marker by using a tilde, ~markerImage.', False)
det_group.add('useAruco3Detection', bool_t, 0, 'enable the new and faster Aruco detection strategy.', False)
det_group.add('minSideLengthCanonicalImg', int_t, 0, 'minimum side length of a marker in the canonical image. Latter is the binarized image in which contours are searched', 32, 0 ,100)
det_group.add('minMarkerLengthRatioOriginalImg', double_t, 0, 'the parameter tau_i has a direct influence on the processing speed. ', 0.0, 0.0 ,1.0)

exit(gen.generate(pkgname='nicol_rh8d', nodename='dataset_collector', name='ArucoDetector'))
